# 大模型领域关键词管理

## 文档说明
- 本文档遵循麦肯锡快速入门原理，收集行业相关的100个关键词，持续迭代维护中。
- 重要程度：⭐（一般）⭐⭐（重要）⭐⭐⭐（核心）
- 状态：🟢（已掌握）🟡（学习中）🔴（待学习）

## 目录
1. [基础概念](#基础概念)
2. [核心技术](#核心技术)
3. [工具方法](#工具方法)
4. [前沿发展](#前沿发展)

状态说明：  
- 🟢 成熟稳定
- 🟡 发展中
- 🔴 实验阶段

## 基础概念
| 关键词 | 重要程度 | 状态 | 简要说明 | 相关资源 |
|-------|---------|------|---------|----------|
| LLM (Large Language Model) | ⭐⭐⭐ | 🟢 | 大规模语言模型，用于处理和生成自然语言的深度学习模型 | [LLM综述](https://arxiv.org/abs/2303.18223) |
| Transformer | ⭐⭐⭐ | 🟢 | 基础架构，是现代大语言模型的核心架构 | [Attention Is All You Need](https://arxiv.org/abs/1706.03762) |
| Token | ⭐⭐⭐ | 🟢 | 文本的基本单位，模型处理的最小单元 | [Tokenization说明](https://huggingface.co/docs/transformers/tokenizer_summary) |
| Embedding | ⭐⭐⭐ | 🟢 | 将文本转换为向量表示的过程 | [Word2Vec论文](https://arxiv.org/abs/1301.3781) |
| Attention | ⭐⭐⭐ | 🟢 | 注意力机制，模型理解上下文关系的核心机制 | [Attention机制详解](https://lilianweng.github.io/posts/2018-06-24-attention/) |
| Context Window | ⭐⭐⭐ | 🟢 | 上下文窗口，模型能处理的最大文本长度 | [长文本论文](https://arxiv.org/abs/2307.02486) |
| Parameter | ⭐⭐⭐ | 🟢 | 模型参数，决定模型能力的关键要素 | [参数高效微调综述](https://arxiv.org/abs/2303.15647) |
| Prompt | ⭐⭐⭐ | 🟢 | 提示词，与模型交互的输入形式 | [提示工程指南](https://www.promptingguide.ai/) |
| Fine-tuning | ⭐⭐⭐ | 🟢 | 微调，使模型适应特定任务的过程 | [微调最佳实践](https://platform.openai.com/docs/guides/fine-tuning) |
| Base Model | ⭐⭐ | 🟢 | 基础模型，未经过特定任务训练的原始模型 | [HuggingFace Models](https://huggingface.co/models) |
| Decoder | ⭐⭐ | 🟡 | 解码器，用于生成文本的模型组件 | [Decoder原理](https://jalammar.github.io/illustrated-transformer/) |
| Encoder | ⭐⭐ | 🟡 | 编码器，用于理解输入文本的模型组件 | [Encoder-Decoder架构](https://jalammar.github.io/illustrated-transformer/) |
| Vocabulary | ⭐⭐ | 🟡 | 词表，模型能识别的所有token集合 | [BPE算法详解](https://huggingface.co/docs/transformers/tokenizer_summary) |
| Checkpoint | ⭐⭐ | 🟡 | 检查点，保存模型训练状态的文件 | [模型检查点指南](https://huggingface.co/docs/transformers/main/model_doc/auto) |
| Architecture | ⭐⭐ | 🟡 | 架构，模型的整体结构设计 | [Transformer架构详解](https://jalammar.github.io/illustrated-transformer/) |


## 核心技术
| 关键词 | 重要程度 | 状态 | 简要说明 | 相关资源 |  
| RLHF | ⭐⭐⭐ | 🟢 | 基于人类反馈的强化学习 | [OpenAI InstructGPT论文](https://arxiv.org/abs/2203.02155) |
|--------|----------|------|-----------|----------|  
| DPO (Direct Preference Optimization) | ⭐⭐⭐ | 🟢 | 直接偏好优化方法，无需强化学习即可利用偏好数据进行微调，是一种新型的模型训练方法 | [DPO论文解读](https://www.cnblogs.com/lemonzhang/p/17910358.html) |  
| PPO (Proximal Policy Optimization) | ⭐⭐⭐ | 🟢 | 近端策略优化算法，是RLHF中最常用的强化学习算法之一，用于优化模型策略 | [OpenAI PPO说明](https://openai.com/research/proximal-policy-optimization) |  
| KTO (Knowledge Transfer Optimization) | ⭐⭐ | 🟡 | 知识迁移优化，用于将预训练模型的知识有效迁移到目标任务中 | [相关论文](https://arxiv.org/) |  
| LoRA | ⭐⭐⭐ | 🟡 | 低秩适应，一种高效的微调方法 | [LoRA论文](https://arxiv.org/abs/2106.09685) |
| QLoRA | ⭐⭐⭐ | 🟡 | 量化版本的LoRA | [QLoRA论文](https://arxiv.org/abs/2305.14314) |

## 工具方法
| 关键词 | 重要程度 | 状态 | 简要说明 | 相关资源 |
|--------|----------|------|-----------|----------|
| Prompt Engineering | ⭐⭐⭐ | 🟢 | 提示词工程，优化模型输入以获得更好结果 | [提示词工程指南](https://www.promptingguide.ai/) |
| RAG | ⭐⭐⭐ | 🟡 | 检索增强生成，提升模型回答准确性 | [RAG论文](https://arxiv.org/abs/2005.11401) |
| Vector Database | ⭐⭐⭐ | 🟡 | 向量数据库，存储和检索文本向量 | [Pinecone文档](https://docs.pinecone.io/) |
| Agent | ⭐⭐ | 🟡 | 智能代理，自主完成任务的AI系统 | [LangChain Agents](https://python.langchain.com/docs/modules/agents/) |
| Function Calling | ⭐⭐ | 🟡 | 函数调用，模型调用外部函数的能力 | [OpenAI函数调用指南](https://platform.openai.com/docs/guides/function-calling) |

## 前沿发展
| 关键词 | 重要程度 | 状态 | 简要说明 | 相关资源 |
|--------|----------|------|-----------|----------|
| Multimodal LLM | ⭐⭐⭐ | 🔴 | 多模态大语言模型，处理文本、图像等多种模态 | [GPT-4V技术报告](https://openai.com/research/gpt-4v-system-card) |
| Small Language Model | ⭐⭐⭐ | 🔴 | 小型语言模型，追求效率与性能平衡 | [Phi-2介绍](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) |
| Long Context | ⭐⭐⭐ | 🔴 | 长文本处理，扩展模型处理更长文本的能力 | [LongNet论文](https://arxiv.org/abs/2307.02486) |
| Code LLM | ⭐⭐⭐ | 🔴 | 代码大模型，专注于代码生成和理解 | [CodeLlama论文](https://arxiv.org/abs/2308.12950) |
| Alignment | ⭐⭐ | 🔴 | 对齐技术，使模型行为符合人类价值观 | [Constitutional AI论文](https://arxiv.org/abs/2212.08073) |

## 注释
1. 定期更新：每月回顾并更新关键词列表
2. 及时补充：发现新的重要概念及时添加
3. 动态调整：根据发展趋势调整重要程度
4. 持续学习：关注状态的变化并更新